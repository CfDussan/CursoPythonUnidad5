{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrupación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Usando .groupby()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método .groupby() de Pandas permite agrupar datos en un DataFrame basado en los valores de una o más columnas. Luego, puedes aplicar una función a cada grupo para obtener resultados como sumas, medias, máximos, mínimos, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sintaxis Básica:\n",
    "\n",
    "# Uso de groupby\n",
    "df.groupby('columna_para_agrupar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de agrupar los datos, puedes aplicar varios métodos de agregación:\n",
    "\n",
    "•.sum(): Suma de valores.\n",
    "\n",
    "•.mean(): Media aritmética.\n",
    "\n",
    "•.median(): Mediana.\n",
    "\n",
    "•.count(): Cuenta el número de valores no nulos.\n",
    "\n",
    "•.max(): Valor máximo.\n",
    "\n",
    "•.min(): Valor mínimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el siguiente ejemplo: Total de días por rango de temperatura en Madrid\n",
    "Agrupación por rangos de valor\n",
    "Aquí, el objetivo es contar cuántos días caen dentro de rangos de temperatura específicos en Madrid. Esto implica crear categorías basadas en los valores de temperatura (por ejemplo, días con temperaturas \"Bajas\", \"Moderadas\" y \"Altas\") y luego contar cuántos días caen en cada categoría.\n",
    "\n",
    "Primero, necesitamos categorizar las temperaturas y luego agrupar y contar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes de inicar\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos primero los archivos\n",
    "archivo_temperaturas = r'C:\\Users\\Administrator\\Documents\\CF\\CIENCIA DE DATOS IA\\Data Analytics\\M4\\Python\\Lecture 5\\temperaturas_globales.csv'\n",
    "df_temperaturas = pd.read_csv(archivo_temperaturas)\n",
    "\n",
    "archivo_precipitaciones = 'C:\\\\Users\\\\Administrator\\\\Documents\\\\CF\\\\CIENCIA DE DATOS IA\\\\Data Analytics\\\\M4\\\\Python\\\\Lecture 5\\\\precipitaciones_globales.csv'\n",
    "df_precipitaciones = pd.read_csv(archivo_precipitaciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temperaturas = pd.read_csv(archivo_temperaturas, parse_dates=['Fecha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Días por rango de temperatura en Madrid:\n",
      "Rango_Temperatura\n",
      "Baja         8\n",
      "Moderada     5\n",
      "Alta        10\n",
      "Muy Alta     1\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_10780\\4276987677.py:5: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dias_por_rango_temperatura = df_temperaturas.groupby('Rango_Temperatura').size() # .size() se utiliza para contar los datos agrupados\n"
     ]
    }
   ],
   "source": [
    "# Categorizando las temperaturas\n",
    "df_temperaturas['Rango_Temperatura'] = pd.cut(df_temperaturas['Madrid'], bins=[-10, 10, 20, 30, 40], labels=[\"Baja\", \"Moderada\", \"Alta\", \"Muy Alta\"])\n",
    "\n",
    "# Contando días por rango de temperatura\n",
    "dias_por_rango_temperatura = df_temperaturas.groupby('Rango_Temperatura').size() # .size() se utiliza para contar los datos agrupados\n",
    "\n",
    "print(\"Días por rango de temperatura en Madrid:\")\n",
    "print(dias_por_rango_temperatura)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función pd.melt()\n",
    "\n",
    "La función pd.melt() se utiliza para \"despivotar\" o transformar un DataFrame de un formato ancho a un formato largo. En un DataFrame ancho, cada variable se extiende a través de las columnas. Al despivotar, convertimos estas columnas en filas, lo que generalmente facilita el trabajo con los datos para ciertos tipos de análisis o visualización.\n",
    "\n",
    "Sintaxis Básica:\n",
    "pd.melt(frame, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de realizar la operación, debemos eliminar la columna Madrid debido a que la misma, recordemos en base a lo realizado anteriormente con groupby, ya no contiene temperaturas sino categorías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columna Madrid\n",
    "df_temperaturas = df_temperaturas.drop('Madrid', axis=1)\n",
    "\n",
    "# Ahora, la columna 'Madrid' ha sido eliminada del DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otra parte, también debemos eliminar las columnas ‘Clasificación_Madrid’ y ‘Rango_Temperatura’, por la misma razón, evitando en este caso inconvenientes en el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Clasificación_Madrid'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Eliminar columna Clasificación_Madrid\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_temperaturas \u001b[38;5;241m=\u001b[39m \u001b[43mdf_temperaturas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mClasificación_Madrid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Ahora, la columna 'Clasificación_Madrid' ha sido eliminada del DataFrame.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Clasificación_Madrid'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Eliminar columna Clasificación_Madrid\n",
    "df_temperaturas = df_temperaturas.drop('Clasificación_Madrid', axis=1)\n",
    "\n",
    "# Ahora, la columna 'Clasificación_Madrid' ha sido eliminada del DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columna Rango_Temperatura\n",
    "df_temperaturas = df_temperaturas.drop('Rango_Temperatura', axis=1)\n",
    "\n",
    "# Ahora, la columna 'Rango_Temperatura' ha sido eliminada del DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, para entender mejor algunas funciones avanzadas de Pandas, necesitamos transformar nuestro DataFrame y organizar los datos con las columnas 'Fecha', 'Ciudad' y 'Temperatura'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Fecha      Ciudad  Temperatura\n",
      "0   2022-01-31  Nueva York            2\n",
      "1   2022-02-28  Nueva York           26\n",
      "2   2022-03-31  Nueva York           20\n",
      "3   2022-04-30  Nueva York           32\n",
      "4   2022-05-31  Nueva York           18\n",
      "..         ...         ...          ...\n",
      "91  2023-08-31     Londres           14\n",
      "92  2023-09-30     Londres            3\n",
      "93  2023-10-31     Londres            2\n",
      "94  2023-11-30     Londres           33\n",
      "95  2023-12-31     Londres           19\n",
      "\n",
      "[96 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Uso de pd.melt()\n",
    "\n",
    "# Transformar las columnas de ciudades en una sola columna 'Ciudad' y una columna 'Temperatura'\n",
    "df_temperaturas_nuevoformato = df_temperaturas.melt(id_vars=['Fecha'], var_name='Ciudad', value_name='Temperatura')\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame transformado\n",
    "\n",
    "print(df_temperaturas_nuevoformato.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este script primero utiliza pd.melt() para \"derretir\" el DataFrame, moviendo los nombres de las ciudades de los encabezados de las columnas a una única columna 'Ciudad', y colocando las temperaturas correspondientes en una columna 'Temperatura'. \n",
    "\n",
    "El argumento id_vars=['Fecha'] se usa para mantener la columna 'Fecha' como está, sin transformarla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformaciones con .groupby()\n",
    "Además de la agregación, puedes realizar transformaciones que mantienen el mismo índice del DataFrame original pero con los datos transformados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centrar las temperaturas por ciudad\n",
    "El objetivo de este ejemplo es ajustar las temperaturas de cada ciudad restando la media de temperatura de esa ciudad a cada registro de temperatura. Esto es una \"transformación\" porque modificamos los datos manteniendo la misma estructura del DataFrame original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Fecha      Ciudad  Temperatura  Temperatura_Centrada\n",
      "0  2022-01-31  Nueva York            2            -14.583333\n",
      "1  2022-02-28  Nueva York           26              9.416667\n",
      "2  2022-03-31  Nueva York           20              3.416667\n",
      "3  2022-04-30  Nueva York           32             15.416667\n",
      "4  2022-05-31  Nueva York           18              1.416667\n"
     ]
    }
   ],
   "source": [
    "# Transformaciones con .groupby()\n",
    "\n",
    "# Calculamos la temperatura media por ciudad\n",
    "media_por_ciudad = df_temperaturas_nuevoformato.groupby('Ciudad')['Temperatura'].transform('mean')\n",
    "\n",
    "# Restamos esta media de cada registro de temperatura para centrar los datos\n",
    "df_temperaturas_nuevoformato['Temperatura_Centrada'] = df_temperaturas_nuevoformato['Temperatura'] - media_por_ciudad\n",
    "\n",
    "# Mostramos las primeras filas para verificar los resultados\n",
    "\n",
    "print(df_temperaturas_nuevoformato.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado en este ejemplo se asigna a una nueva columna en el DataFrame, preservando la estructura original del DataFrame mientras se modifica el contenido de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrado con .groupby()\n",
    "\n",
    "También puedes filtrar grupos basado en propiedades de los grupos usando .filter()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrar ciudades con variabilidad de temperatura superior al umbral\n",
    "Aquí, el objetivo es filtrar y mantener sólo aquellas ciudades cuya desviación estándar de la temperatura (una medida de variabilidad) exceda un cierto umbral. Esto implica \"filtrar\" grupos basándonos en una propiedad calculada para el grupo entero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciudades con alta variabilidad de temperatura:\n",
      "['Nueva York' 'París' 'Berlín' 'Londres']\n"
     ]
    }
   ],
   "source": [
    "# Definimos un umbral para la desviación estándar de la temperatura\n",
    "umbral_variabilidad = 5\n",
    "\n",
    "# Filtramos ciudades con una variabilidad de temperatura superior al umbral\n",
    "ciudades_con_alta_variabilidad = df_temperaturas_nuevoformato.groupby('Ciudad').filter(lambda x: x['Temperatura'].std() > umbral_variabilidad)\n",
    "\n",
    "print(\"Ciudades con alta variabilidad de temperatura:\")\n",
    "\n",
    "print(ciudades_con_alta_variabilidad['Ciudad'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, .filter() se usa para aplicar una función lambda a cada grupo. La función calcula la desviación estándar de las temperaturas para cada ciudad y compara este valor con un umbral predefinido. Solo los grupos (ciudades) que cumplen con la condición (variabilidad de temperatura superior al umbral) se mantienen en el DataFrame resultante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot tables\n",
    "\n",
    "Las tablas pivote son una herramienta excelente para resumir, analizar, explorar y presentar tus datos. Pandas facilita la creación de tablas pivote a partir de DataFrames, permitiéndote ver la relación entre dos dimensiones de datos de manera compacta. Son especialmente útiles para análisis de datos exploratorios y reportes.\n",
    "# Crear una tabla pivote\n",
    "pivot = df.pivot_table(values='valor', index='fila', columns='columna', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurándonos de que la columna 'Fecha' sea del tipo datetime\n",
    "df_temperaturas_nuevoformato['Fecha'] = pd.to_datetime(df_temperaturas_nuevoformato['Fecha'])\n",
    "#Toco investigar porque se presentaba un error pues todo el proceso anterior se realizo en otro archivo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperatura máxima anual para cada ciudad\n",
    "Supongamos que queremos crear una tabla pivote que muestre la temperatura máxima anual para cada ciudad registrada en nuestro DataFrame df_temperaturas_nuevoformato. Esta tabla nos permitirá comparar fácilmente las temperaturas máximas entre ciudades a lo largo de los años."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla Pivote de Temperaturas Máximas Anuales por Ciudad:\n",
      "Ciudad  Berlín  Londres  Nueva York  París\n",
      "Año                                       \n",
      "2022        33       31          32     31\n",
      "2023        34       34          33     33\n"
     ]
    }
   ],
   "source": [
    "# Primero, asegurémonos de que el DataFrame tiene una columna 'Año' extraída de 'Fecha'\n",
    "df_temperaturas_nuevoformato['Año'] = df_temperaturas_nuevoformato['Fecha'].dt.year\n",
    "\n",
    "\n",
    "# Crear la tabla pivote\n",
    "tabla_pivote_maximas = df_temperaturas_nuevoformato.pivot_table(values='Temperatura', index='Año', columns='Ciudad', aggfunc='max')\n",
    "\n",
    "print(\"Tabla Pivote de Temperaturas Máximas Anuales por Ciudad:\")\n",
    "\n",
    "print(tabla_pivote_maximas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este ejemplo utiliza pivot_table para crear una tabla que tiene años en las filas (index='Año'), ciudades en las columnas (columns='Ciudad'), y las temperaturas máximas como valores (values='Temperatura'). La función de agregación aggfunc='max' se utiliza para asegurar que estamos viendo la temperatura máxima registrada cada año para cada ciudad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparación de temperaturas medias y máximas mensuales en Madrid\n",
    "Si estamos interesados en comparar no solo las temperaturas máximas sino también las medias en un formato mensual para una ciudad específica, como Nueva York, podríamos adaptar nuestra tabla pivote de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla Pivote de Temperaturas Medias y Máximas Mensuales en Nueva York:\n",
      "     max  mean\n",
      "Mes           \n",
      "1     25  13.5\n",
      "2     26  10.5\n",
      "3     20  15.0\n",
      "4     32  25.5\n",
      "5     19  18.5\n",
      "6     11   9.5\n",
      "7      8   7.0\n",
      "8     24  13.5\n",
      "9     28  15.5\n",
      "10    28  24.5\n",
      "11    33  26.5\n",
      "12    32  19.5\n"
     ]
    }
   ],
   "source": [
    "# Primero, asegurémonos de que el DataFrame tiene una columna 'Mes' extraída de 'Fecha'\n",
    "df_temperaturas_nuevoformato['Mes'] = df_temperaturas_nuevoformato['Fecha'].dt.month\n",
    "\n",
    "\n",
    "# Crear la tabla pivote para Nueva York con temperaturas medias y máximas\n",
    "tabla_pivote_nuevayork = df_temperaturas_nuevoformato[df_temperaturas_nuevoformato['Ciudad'] == 'Nueva York'].pivot_table(values='Temperatura',\n",
    "\n",
    "                                                                                          index='Mes',\n",
    "\n",
    "                                                                                          aggfunc={'Temperatura': ['mean', 'max']})\n",
    "\n",
    "\n",
    "print(\"Tabla Pivote de Temperaturas Medias y Máximas Mensuales en Nueva York:\")\n",
    "\n",
    "print(tabla_pivote_nuevayork)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este ejemplo filtra primero los datos para Nueva York, luego crea una tabla pivote donde cada fila representa un mes del año. Utiliza dos funciones de agregación, mean y max, para calcular la temperatura media y máxima, respectivamente, para cada mes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos ejemplos demuestran la flexibilidad y la capacidad de las tablas pivote en Pandas para resumir y analizar datos. Al ajustar los parámetros values, index, columns, y aggfunc, puedes adaptar las tablas pivote a una amplia variedad de situaciones de análisis de datos, facilitando la comprensión de las relaciones y tendencias en tus datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fusión y concatenación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fusión de datos con merge()\n",
    "\n",
    "pd.merge() es similar a las operaciones JOIN en SQL y combina filas de dos o más DataFrames basados en una o más claves de coincidencia.\n",
    "\n",
    "# Fusionar DataFrames en una clave común\n",
    "df_fusionado = pd.merge(df1, df2, on='clave_comun')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a los dos DataFrames credos, df_temperaturas y df_precipitaciones, ambos DataFrames tienen una columna común 'Fecha' y una columna para cada ciudad con los valores de temperatura y precipitación, respectivamente. Queremos fusionar estos dos DataFrames para analizar las temperaturas y las precipitaciones juntas.\n",
    "\n",
    "Antes de continuar necesitas asegurarte de que ambas columnas 'Fecha' en los DataFrames df_temperaturas y df_precipitaciones tengan el mismo tipo de datos, específicamente datetime64[ns], antes de proceder con el merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurando que los datos estén en el formato correcto\n",
    "\n",
    "df_temperaturas['Fecha'] = pd.to_datetime(df_temperaturas['Fecha'])\n",
    "\n",
    "df_precipitaciones['Fecha'] = pd.to_datetime(df_precipitaciones['Fecha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Fecha  Nueva York_temp  París_temp  Berlín_temp  Londres_temp  \\\n",
      "0 2022-01-31                2           6           22            24   \n",
      "1 2022-02-28               26          29           18            10   \n",
      "2 2022-03-31               20           3           14             2   \n",
      "3 2022-04-30               32          -4           26            31   \n",
      "4 2022-05-31               18           0           33             1   \n",
      "\n",
      "   Madrid_temp  Nueva York_prec  París_prec  Berlín_prec  Londres_prec  \\\n",
      "0           23               63          78           33            99   \n",
      "1           21               78          34           76            57   \n",
      "2           -4               35          23           74            52   \n",
      "3           33               33          75           90            88   \n",
      "4           26               80          81           85            49   \n",
      "\n",
      "   Madrid_prec  \n",
      "0           82  \n",
      "1           86  \n",
      "2           58  \n",
      "3           65  \n",
      "4           49  \n"
     ]
    }
   ],
   "source": [
    "# Una vez que ambos están en formato datetime, procedemos con el merge\n",
    "# Combinar df_temperaturas y df_precipitaciones\n",
    "\n",
    "df_combinado = pd.merge(df_temperaturas, df_precipitaciones, on='Fecha', suffixes=('_temp', '_prec'))\n",
    "\n",
    "# Mostrando las primeras filas del DataFrame combinado\n",
    "\n",
    "print(df_combinado.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, pd.merge() fusiona df_temperaturas y df_precipitaciones usando la columna 'Fecha' como clave de fusión. Los sufijos _temp y _prec se añaden a los nombres de las columnas para distinguir entre las temperaturas y las precipitaciones de cada ciudad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenación con concat()\n",
    "\n",
    "pd.concat() concatena DataFrames o Series a lo largo de un eje particular. Es útil para combinar datos que tienen el mismo esquema.\n",
    "\n",
    "# Concatenar DataFrames verticalmente\n",
    "df_concatenado = pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ilustrar el uso de pd.concat, vamos a crear dos DataFrames separados como si fueran segmentos de datos de temperatura para diferentes años y ciudades. Luego, mostraremos cómo concatenar estos DataFrames para combinar los datos en una sola estructura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 1\n",
    "Creación de los DataFrames para concatenación\n",
    "Vamos a simular dos conjuntos de datos:\n",
    "\n",
    "DataFrame 1: Temperaturas del año 2022 para Nueva York y París.\n",
    "DataFrame 2: Temperaturas del año 2023 para las mismas ciudades.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_10780\\549123114.py:4: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  'Fecha': pd.date_range(start=\"2022-01-01\", end=\"2022-12-31\", freq='M'),\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_10780\\549123114.py:13: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  'Fecha': pd.date_range(start=\"2023-01-01\", end=\"2023-12-31\", freq='M'),\n"
     ]
    }
   ],
   "source": [
    "# Datos para el primer DataFrame (2022)\n",
    "\n",
    "data_2022 = {\n",
    "    'Fecha': pd.date_range(start=\"2022-01-01\", end=\"2022-12-31\", freq='M'),\n",
    "    'Nueva York': [-5, 0, 5, 10, 15, 20, 25, 24, 19, 10, 5, -2],\n",
    "    'París': [2, 5, 8, 12, 15, 18, 21, 20, 17, 11, 7, 3]\n",
    "}\n",
    "\n",
    "df_2022 = pd.DataFrame(data_2022)\n",
    "\n",
    "# Datos para el segundo DataFrame (2023)\n",
    "data_2023 = {\n",
    "    'Fecha': pd.date_range(start=\"2023-01-01\", end=\"2023-12-31\", freq='M'),\n",
    "    'Nueva York': [-6, -1, 4, 11, 16, 21, 26, 23, 18, 9, 4, -3],\n",
    "    'París': [1, 4, 9, 13, 16, 19, 22, 21, 16, 10, 6, 2]\n",
    "}\n",
    "\n",
    "df_2023 = pd.DataFrame(data_2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos df_2022 y df_2023, cada uno conteniendo datos de temperatura para un año específico, vamos a concatenarlos para formar un único DataFrame que contenga los datos de ambos años."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 2\n",
    "Concatenación de los DataFrames\n",
    "Para concatenar los dos DataFrames, utilizaremos pd.concat(), lo que nos permitirá unirlos verticalmente (uno encima del otro), asumiendo que tienen las mismas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Fecha  Nueva York  París\n",
      "0  2022-01-31          -5      2\n",
      "1  2022-02-28           0      5\n",
      "2  2022-03-31           5      8\n",
      "3  2022-04-30          10     12\n",
      "4  2022-05-31          15     15\n",
      "5  2022-06-30          20     18\n",
      "6  2022-07-31          25     21\n",
      "7  2022-08-31          24     20\n",
      "8  2022-09-30          19     17\n",
      "9  2022-10-31          10     11\n",
      "10 2022-11-30           5      7\n",
      "11 2022-12-31          -2      3\n",
      "12 2023-01-31          -6      1\n",
      "13 2023-02-28          -1      4\n",
      "14 2023-03-31           4      9\n",
      "15 2023-04-30          11     13\n",
      "16 2023-05-31          16     16\n",
      "17 2023-06-30          21     19\n",
      "18 2023-07-31          26     22\n",
      "19 2023-08-31          23     21\n",
      "20 2023-09-30          18     16\n",
      "21 2023-10-31           9     10\n",
      "22 2023-11-30           4      6\n",
      "23 2023-12-31          -3      2\n"
     ]
    }
   ],
   "source": [
    "# Concatenando los DataFrames verticalmente\n",
    "df_temperaturas = pd.concat([df_2022, df_2023])\n",
    "\n",
    "# Reiniciamos el índice del DataFrame resultante para evitar índices duplicados\n",
    "df_temperaturas.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(df_temperaturas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Filtrado con isin()\n",
    "\n",
    "Uno de los métodos de filtrados más utilizados en Pandas es isin(), el cual permite seleccionar filas de un DataFrame o Series donde un valor o conjunto de valores específicos, aparecen en una columna (o índice en el caso de Series). Es particularmente útil cuando quieres filtrar tu DataFrame para incluir sólo ciertos registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Fecha      Ciudad  Temperatura   Año  Mes\n",
      "0  2022-01-31  Nueva York            2  2022    1\n",
      "1  2022-02-28  Nueva York           26  2022    2\n",
      "2  2022-03-31  Nueva York           20  2022    3\n",
      "3  2022-04-30  Nueva York           32  2022    4\n",
      "4  2022-05-31  Nueva York           18  2022    5\n",
      "5  2022-06-30  Nueva York           11  2022    6\n",
      "6  2022-07-31  Nueva York            8  2022    7\n",
      "7  2022-08-31  Nueva York            3  2022    8\n",
      "8  2022-09-30  Nueva York            3  2022    9\n",
      "9  2022-10-31  Nueva York           28  2022   10\n",
      "10 2022-11-30  Nueva York           20  2022   11\n",
      "11 2022-12-31  Nueva York            7  2022   12\n",
      "12 2023-01-31  Nueva York           25  2023    1\n",
      "13 2023-02-28  Nueva York           -5  2023    2\n",
      "14 2023-03-31  Nueva York           10  2023    3\n",
      "15 2023-04-30  Nueva York           19  2023    4\n",
      "16 2023-05-31  Nueva York           19  2023    5\n",
      "17 2023-06-30  Nueva York            8  2023    6\n",
      "18 2023-07-31  Nueva York            6  2023    7\n",
      "19 2023-08-31  Nueva York           24  2023    8\n",
      "20 2023-09-30  Nueva York           28  2023    9\n",
      "21 2023-10-31  Nueva York           21  2023   10\n",
      "22 2023-11-30  Nueva York           33  2023   11\n",
      "23 2023-12-31  Nueva York           32  2023   12\n",
      "72 2022-01-31     Londres           24  2022    1\n",
      "73 2022-02-28     Londres           10  2022    2\n",
      "74 2022-03-31     Londres            2  2022    3\n",
      "75 2022-04-30     Londres           31  2022    4\n",
      "76 2022-05-31     Londres            1  2022    5\n",
      "77 2022-06-30     Londres           25  2022    6\n",
      "78 2022-07-31     Londres           22  2022    7\n",
      "79 2022-08-31     Londres           15  2022    8\n",
      "80 2022-09-30     Londres           19  2022    9\n",
      "81 2022-10-31     Londres           11  2022   10\n",
      "82 2022-11-30     Londres           -1  2022   11\n",
      "83 2022-12-31     Londres            7  2022   12\n",
      "84 2023-01-31     Londres           34  2023    1\n",
      "85 2023-02-28     Londres           28  2023    2\n",
      "86 2023-03-31     Londres           19  2023    3\n",
      "87 2023-04-30     Londres           -2  2023    4\n",
      "88 2023-05-31     Londres           34  2023    5\n",
      "89 2023-06-30     Londres            9  2023    6\n",
      "90 2023-07-31     Londres            6  2023    7\n",
      "91 2023-08-31     Londres           14  2023    8\n",
      "92 2023-09-30     Londres            3  2023    9\n",
      "93 2023-10-31     Londres            2  2023   10\n",
      "94 2023-11-30     Londres           33  2023   11\n",
      "95 2023-12-31     Londres           19  2023   12\n"
     ]
    }
   ],
   "source": [
    "#Siguiendo nuestro caso:\n",
    "\n",
    "# A partir de nuestro df, creamos un nuevo df que contenga los registros de Londres y Nueva York.\n",
    "\n",
    "temperaturas_madrid = df_temperaturas_nuevoformato[df_temperaturas_nuevoformato['Ciudad'].isin(['Londres', 'Nueva York'])]\n",
    "print(temperaturas_madrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformaciones con groupby() y Funciones Lambda\n",
    "\n",
    "Las transformaciones con .groupby() y funciones lambda en Pandas te permiten aplicar operaciones complejas a los subconjuntos de datos agrupados, manteniendo la estructura original del DataFrame. Esto es especialmente útil cuando necesitas normalizar o estandarizar datos dentro de grupos o aplicar cualquier transformación que dependa del contexto de cada grupo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalización de las temperaturas por ciudad\n",
    "Objetivo: Normalizar las temperaturas para cada ciudad en el DataFrame de temperaturas, asegurando que cada valor de temperatura se ajuste a la escala de su grupo. La normalización aquí significa restar la media del grupo a cada valor y luego dividir por la desviación estándar del grupo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 1: Creación de una función Lambda para la normalización\n",
    "Para este ejemplo, la función lambda tomará cada grupo (es decir, las temperaturas de cada ciudad), restará la media de ese grupo a cada elemento y luego dividirá el resultado por la desviación estándar del grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando groupby() junto con transform() para aplicar la normalización\n",
    "df_temperaturas_nuevoformato['Temperatura_Normalizada'] = df_temperaturas_nuevoformato.groupby('Ciudad')['Temperatura'].transform(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Fecha      Ciudad  Temperatura   Año  Mes  Temperatura_Normalizada\n",
      "0  2022-01-31  Nueva York            2  2022    1                -1.333729\n",
      "1  2022-02-28  Nueva York           26  2022    2                 0.861208\n",
      "2  2022-03-31  Nueva York           20  2022    3                 0.312474\n",
      "3  2022-04-30  Nueva York           32  2022    4                 1.409942\n",
      "4  2022-05-31  Nueva York           18  2022    5                 0.129562\n",
      "..        ...         ...          ...   ...  ...                      ...\n",
      "91 2023-08-31     Londres           14  2023    8                -0.102538\n",
      "92 2023-09-30     Londres            3  2023    9                -1.035990\n",
      "93 2023-10-31     Londres            2  2023   10                -1.120850\n",
      "94 2023-11-30     Londres           33  2023   11                 1.509788\n",
      "95 2023-12-31     Londres           19  2023   12                 0.321758\n",
      "\n",
      "[96 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_temperaturas_nuevoformato)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código agrupa el DataFrame por 'Ciudad', y para cada grupo de temperaturas de la ciudad, aplica la transformación especificada por la función lambda. El resultado es una serie de temperaturas normalizadas que se añade al DataFrame original como una nueva columna llamada 'Temperatura_Normalizada'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 2: visualización de los resultados\n",
    "Para ver cómo se ha aplicado la normalización a nuestros datos, podemos imprimir las primeras filas del DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Ciudad  Temperatura  Temperatura_Normalizada\n",
      "0  Nueva York            2                -1.333729\n",
      "1  Nueva York           26                 0.861208\n",
      "2  Nueva York           20                 0.312474\n",
      "3  Nueva York           32                 1.409942\n",
      "4  Nueva York           18                 0.129562\n"
     ]
    }
   ],
   "source": [
    "print(df_temperaturas_nuevoformato[['Ciudad', 'Temperatura', 'Temperatura_Normalizada']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este paso simplemente muestra las temperaturas originales y las normalizadas lado a lado para cada ciudad, permitiéndote ver el efecto de la normalización."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
